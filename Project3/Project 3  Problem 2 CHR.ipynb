{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pyaudio, wave\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "class MFCC:\n",
    "    def __init__(self,overlap_time=0.01,segment_time=0.02,window_mode=\"Hamming\",Mel_setting=None,normalize_flag=False):\n",
    "        self.segment_time=segment_time\n",
    "        self.overlap_time=overlap_time\n",
    "        self.Mel_setting=Mel_setting\n",
    "        self.lower_boundHz=0\n",
    "        self.upper_boundHz=8000\n",
    "        self.num_banks=40\n",
    "        self.num_ceps=13\n",
    "        self.mode=window_mode\n",
    "        self.normalize=normalize_flag\n",
    "        if self.Mel_setting !=None:\n",
    "            self.lower_boundHz=self.Mel_setting[\"lower_boundHz\"]\n",
    "            self.upper_boundHz=self.Mel_setting[\"upper_boundHz\"]\n",
    "            self.num_banks=self.Mel_setting[\"num_banks\"]\n",
    "            self.num_ceps=self.Mel_setting[\"num_ceps\"]\n",
    "    #Apply window function to the frames\n",
    "    def wave2frames(self):\n",
    "        width=int(self.rate*self.segment_time)\n",
    "        stride=int(self.rate*self.overlap_time)\n",
    "        # you can use np.ceil(log2 width) as the power of FFT \n",
    "        self.FFT_size=int(np.power(2,np.ceil(np.log2(width))))\n",
    "        wave_length=len(self.wave)\n",
    "        if wave_length<=width:\n",
    "            num_frames=1\n",
    "        else:\n",
    "            num_frames=int(np.ceil((wave_length-width)/stride))+1\n",
    "        self.frames=[]    \n",
    "        for i in range(num_frames):\n",
    "            self.frames.append(self.wave[stride*i:stride*i+width])\n",
    "        \n",
    "        \n",
    "    def Preemphasizing(self):\n",
    "        #input is the chunk with length set to 1600, it could also be the whole signal document (preferred)\n",
    "        pe=np.zeros(len(self.wave))\n",
    "        pe[0]=self.wave[0]\n",
    "        for i in range(1,len(self.wave)):\n",
    "            pe[i]=self.wave[i]-0.95*self.wave[i-1]\n",
    "        self.wave=pe\n",
    "        \n",
    "        \n",
    "    def windowing(self,mode=\"Hamming\"):\n",
    "        #do windowing for the signal frame\n",
    "        n=len(self.frames[0])\n",
    "        #windowing the speech signal\n",
    "        if self.mode==\"Hamming\":\n",
    "            self.frames=self.frames*np.hamming(n)\n",
    "        elif self.mode==\"Hanning\":\n",
    "            self.frames=self.frames*np.hanning(n)\n",
    "        elif self.mode==\"Blackman\":\n",
    "            self.frames=self.frames*np.blackman(n)\n",
    "\n",
    "\n",
    "    #Pad zero to make the frame a desired length (exponential of 2)\n",
    "    def zero_padding(self):\n",
    "        #zero padding for FFT\n",
    "        frame_length=len(self.frames[0])\n",
    "        num_frames=len(self.frames)\n",
    "        padding_length=self.FFT_size-frame_length\n",
    "        zeros=np.zeros([num_frames,padding_length])\n",
    "        print(frame_length)\n",
    "        print(num_frames)\n",
    "        print(zeros.shape)\n",
    "        print(np.array(self.frames).shape)\n",
    "        self.frames=np.concatenate((self.frames,zeros),axis=1)\n",
    "        print(self.frames.shape)\n",
    "\n",
    "    #Fast-Fourier Transform\n",
    "    def FFT(self):\n",
    "        #http://dong.sh/posts/difffftandrfft/\n",
    "        #we use the rfft rather than the fft, the difference is shown in the website above.\n",
    "        # in short rfft give a result of half of the self.FFT_size\n",
    "        mag_frames = np.absolute(np.fft.rfft(self.frames, self.FFT_size))  # Magnitude of the FFT\n",
    "        self.power_spectrum = ((1.0 / self.FFT_size) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "        print(self.power_spectrum.shape)\n",
    "\n",
    "    #Herz to Mel\n",
    "    def hz2mel(self, f):\n",
    "        #  Convert frequencies f (in Hz) to mel 'scale'.\n",
    "        #Mel warping function\n",
    "        z = 2595 * np.log10(1+f/700);\n",
    "        return z\n",
    "\n",
    "    #Mel to Herz\n",
    "    def mel2hz(self, z):\n",
    "        # Convert 'mel scale' frequencies into Hz\n",
    "        f = 700*(np.power(10,z/2595)-1)  #CHR use np.power to simulate \".^\" in matlab\n",
    "        return f\n",
    "\n",
    "    \n",
    "                                                             \n",
    "                                                             \n",
    "    def filterbanks(self):\n",
    "        upper_boundMel=self.hz2mel(self.upper_boundHz)\n",
    "        lower_boundMel=self.hz2mel(self.lower_boundHz)\n",
    "        #Uniformly sample in Mel scale to get 40 triangular filters\n",
    "        mel_points=np.linspace(lower_boundMel,upper_boundMel,self.num_banks+2)\n",
    "        #Transform to frequency scale and generate non-uniformly distributed triangular filters\n",
    "        hz_points=self.mel2hz(mel_points)\n",
    "        #After FFT, the sample become half of the original (integer)\n",
    "        bin=np.floor((self.FFT_size + 1)/2*hz_points/(self.upper_boundHz-self.lower_boundHz))\n",
    "        #Correspond the frequency points to the power spectrum after FFT\n",
    "       #print(bin)\n",
    "        #Normalization because of the lower bound\n",
    "        bin=bin-bin[0]\n",
    "        fbank=np.zeros((self.num_banks,int(np.floor(self.FFT_size/2+1))))\n",
    "        for m in range(1,self.num_banks+1):\n",
    "            f_m_low=int(bin[m-1])   # left\n",
    "            f_m_center=int(bin[m])  # center\n",
    "            f_m_up=int(bin[m+1])    # right\n",
    "            for k in range(f_m_low,f_m_center):\n",
    "                fbank[m-1,k]=(k-bin[m-1])/(bin[m]-bin[m-1])\n",
    "            for k in range(f_m_center,f_m_up):\n",
    "                fbank[m-1,k]=(bin[m+1]-k)/(bin[m+1]-bin[m])\n",
    "        #Dot product\n",
    "        Fb=np.dot(self.power_spectrum,fbank.T)\n",
    "        #eps is a small float number. when Fb is 0, Fb is eps. this is to avoid error in division\n",
    "        Fb=np.where(Fb==0,np.finfo(float).eps,Fb) # Numerical Stability\n",
    "\n",
    "        #Log Mel spectrum\n",
    "        #Compress values\n",
    "        self.Log_Mel_spectrum=10*np.log(Fb) \n",
    "\n",
    "    def cal_delta(self):\n",
    "        self.mfcc[0]=np.hstack((self.mfcc[0],self.mfcc[0],self.mfcc[0]))\n",
    "        self.mfcc[-1]=np.hstack((self.mfcc[-1],self.mfcc[-1],self.mfcc[-1]))\n",
    "\n",
    "        for i in range(1,len(self.mfcc)-1):\n",
    "            delta=np.zeros(13)\n",
    "            for j in range(13):\n",
    "                delta[j]=self.mfcc[i+1][j]-self.mfcc[i-1][j]\n",
    "            self.mfcc[i]=np.hstack((self.mfcc[i],delta))\n",
    "\n",
    "        for i in range(1,len(self.mfcc)-1):\n",
    "            acc=np.zeros(13)\n",
    "            for j in range(13):\n",
    "                acc[j]=self.mfcc[i+1][13+j]-self.mfcc[i-1][13+j]\n",
    "            self.mfcc[i]=np.hstack((self.mfcc[i],acc))\n",
    "                \n",
    "    def normalization(self):\n",
    "        #对mfcc_feat 归一化\n",
    "        mean, std = np.mean(self.mfcc), np.std(self.mfcc)\n",
    "        self.mfcc = (self.mfcc-mean) / std\n",
    "    \n",
    "    def getMFCC(self,wave,rate=16000):\n",
    "        self.wave=wave\n",
    "        self.rate=rate\n",
    "        self.Preemphasizing()\n",
    "        self.wave2frames()\n",
    "        self.windowing()\n",
    "        self.zero_padding()\n",
    "        self.FFT()\n",
    "        self.filterbanks()\n",
    "        self.mfcc=dct(self.Log_Mel_spectrum, type=2,axis=1, norm='ortho')[:,0 : 13].tolist()\n",
    "        self.cal_delta()\n",
    "        if self.normalize:\n",
    "            self.normalization()\n",
    "            \n",
    "        return self.mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC PART\n",
    "\n",
    "Here, I write three functions to get MFCC feature (39 dim) one is from project 2 another two functions are made of librosa and python_speech_features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMFCC(wavename):\n",
    "    # It runs tooo slow\n",
    "    import numpy as np\n",
    "    import scipy.io.wavfile as wav\n",
    "    fs, audio = wav.read(wavename)\n",
    "    my_mfcc=MFCC(normalize_flag=True)\n",
    "    mfccs=my_mfcc.getMFCC(audio,fs)\n",
    "    return np.array(mfccs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMFCC2(wavename):#with normalization\n",
    "    import numpy as np\n",
    "    import scipy.io.wavfile as wav\n",
    "    from python_speech_features import mfcc\n",
    "    fs, audio = wav.read(wavename)\n",
    "    feature_mfcc = mfcc(audio, samplerate=fs,\n",
    "                        winlen=0.020,\n",
    "               winstep=0.01,\n",
    "               numcep=13,\n",
    "               nfilt=40,\n",
    "               nfft=512,\n",
    "               lowfreq=133.33,\n",
    "               highfreq=6855.4976,\n",
    "               preemph=0.95,\n",
    "               ceplifter=0,\n",
    "               appendEnergy=False,\n",
    "               winfunc=np.hamming)\n",
    "    mfcc=[]\n",
    "    mfcc.append(np.hstack([feature_mfcc[0],feature_mfcc[0],feature_mfcc[0]]))\n",
    "    for i in range(1,len(feature_mfcc)-1):\n",
    "        delta=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            delta[j]=feature_mfcc[i+1][j]-feature_mfcc[i-1][j]\n",
    "        mfcc.append(np.hstack([feature_mfcc[i],delta]))\n",
    "    mfcc.append(np.hstack([feature_mfcc[-1],feature_mfcc[-1],feature_mfcc[-1]]))\n",
    "\n",
    "    for i in range(1,len(mfcc)-1):\n",
    "        acc=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            acc[j]=mfcc[i+1][13+j]-mfcc[i-1][13+j]\n",
    "        mfcc[i]=np.hstack([mfcc[i],acc])\n",
    "    mfccs=np.array(mfcc)\n",
    "    std=np.std(mfccs)\n",
    "    var=np.var(mfccs,1)\n",
    "    for i in range(len(mfccs)):\n",
    "        for j in range(39):\n",
    "            mfccs[i][j]=mfccs[i][j]/var[i]\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMFCC3(wavename):#with normalization\n",
    "    import librosa\n",
    "    audio, sr = librosa.load(wavename,sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr,n_mfcc=39)\n",
    "    std=np.std(mfccs)\n",
    "    var=np.var(mfccs,1)\n",
    "    for i in range(len(mfccs)):\n",
    "        for j in range(39):\n",
    "            mfccs[i][j]=mfccs[i][j]/var[i]\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Templates\n",
    "\n",
    "\n",
    "There are total 100 wave files, 10 samples for digit 1-10. All these files are saved in the following format by Huangrui Chu: digit_0.wav, digit_1.wav.  digit could be 0,1,2,...9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_templates(foldername,start_instance,end_instance):\n",
    "    #we could also use this function for project 1,2,3 for testing our algorithm\n",
    "    #INPUT:\n",
    "        #foldername: the name of folder where Huangrui save the audio files\n",
    "        #end-start:the number of instance we are expected to use as the templates.\n",
    "    #OUTPUT:\n",
    "        #templates: we can easily fetch the template for the corresponding digit using:\n",
    "                #len(templates)%10+digit\n",
    "    templates=[]\n",
    "    max_template_length=0\n",
    "    for i_th_instance in range(start_instance,end_instance):\n",
    "        for digit in range(0,10):\n",
    "            #print(str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            mfcc=getMFCC2(foldername+\"/\"+str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            if max_template_length<len(mfcc):\n",
    "                max_template_length=len(mfcc)\n",
    "            templates.append(mfcc)\n",
    "    return templates,max_template_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_templates2(foldername,start_instance,end_instance):\n",
    "    #we could also use this function for project 1,2,3 for testing our algorithm\n",
    "    #INPUT:\n",
    "        #foldername: the name of folder where Huangrui save the audio files\n",
    "        #end-start:the number of instance we are expected to use as the templates.\n",
    "    #OUTPUT:\n",
    "        #templates: we can easily fetch the template for the corresponding digit using:\n",
    "                #len(templates)%10+digit\n",
    "    digits=[\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]\n",
    "    templates=[]\n",
    "    max_template_length=0\n",
    "    for i_th_instance in range(start_instance,end_instance):\n",
    "        for digit in digits:\n",
    "            #print(str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            mfcc=getMFCC2(foldername+\"/\"+digit+'_'+str(i_th_instance)+'.wav')\n",
    "            if max_template_length<len(mfcc):\n",
    "                max_template_length=len(mfcc)\n",
    "            templates.append(mfcc)\n",
    "    return templates,max_template_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 K Means Hard Version\n",
    "\n",
    "Use the segmental K-means procedure to train an HMM for each of the digits\n",
    "(using the 5 \"training\" recordings you have for them). Assume each state to\n",
    "have a single Gaussian distribution, and the HMM for each digit to have 5\n",
    "states. Recognize the 5 test utterances using the HMM models and report\n",
    "recognition accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def traceback(D):\n",
    "    #start from the last state and last frame\n",
    "    current_state,current_frame=np.array(D.shape)-1\n",
    "    #insert the last frame's state\n",
    "    x=[current_state]\n",
    "    \n",
    "    #print(current_frame+1)\n",
    "    # we do not need the frame 0, which is the fine\n",
    "    while current_state>0 and current_frame>1:\n",
    "        #move to the previous frame\n",
    "        current_frame-=1\n",
    "        #print(current_state)\n",
    "        if current_state>2:\n",
    "            to_check=[D[current_state][current_frame-1],\n",
    "                      D[current_state-1][current_frame-1],\n",
    "                      D[current_state-2][current_frame-1]]\n",
    "            track=np.argmin(to_check)\n",
    "        elif current_state>1:\n",
    "            to_check=[D[current_state][current_frame-1],\n",
    "                      D[current_state-1][current_frame-1]]\n",
    "            track=np.argmin(to_check)\n",
    "        else:\n",
    "            track=0\n",
    "            \n",
    "        if track==0:\n",
    "            #which means, last frame still in the same stage\n",
    "            x.insert(0,current_state)\n",
    "        elif track==1:\n",
    "            current_state-=1\n",
    "            x.insert(0,current_state)\n",
    "        else:\n",
    "            current_state-=2\n",
    "            x.insert(0,current_state)\n",
    "    #print(x)\n",
    "    \n",
    "#     print(len(x))\n",
    "#    print(np.bincount(x, weights=None, minlength=0))\n",
    "#     print()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gaussian(mu,squared_sigma,input_vector):\n",
    "    #Author: Huangrui Chu, \n",
    "    #Calculate the cost using log gaussian\n",
    "    part1=0.5*np.sum(np.log((2*np.pi)*(squared_sigma)))\n",
    "    part2=0.5*np.sum(np.square((input_vector-mu))/squared_sigma)\n",
    "    cost= part1+part2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Kmean_dtw(model_vectors,data,T,cov_cent,get_track=False):\n",
    "    #Author: Huangrui Chu\n",
    "    #Input, T is the transition_score\n",
    "    #yes, we use cost!!!!!!!!\n",
    "    #Output: the path, how we align each node\n",
    "    # insert fin at the beginning of the template and data\n",
    "    zeros=np.zeros([39])\n",
    "    model_vectors=np.vstack([zeros,model_vectors])\n",
    "    #这边对应的是不是我的cov 要append1？？？???????????????????????????????????\n",
    "    ones=np.zeros([39])+1\n",
    "    cov_cent=np.vstack([ones,cov_cent])\n",
    "    data=np.vstack([zeros,data])\n",
    "    #print(data.shape)\n",
    "\n",
    "    t=len(model_vectors) # here, t should be the number of states+1 we set\n",
    "    d=len(data)#means input frame j\n",
    "    #create empty best path cost matrix \"P\" \n",
    "    P=np.zeros([t,d])\n",
    "    #to fetch the data, we use P[i][j],i for template and j for input data\n",
    "#     • P i,j = best path cost from origin to node [i,j]\n",
    "#     • C i,j = local node cost of aligning template frame i to input frame j\n",
    "#     • T i,j,k,l = Edge cost from node (i,j) to node (k,l)\n",
    "\n",
    "    for j in range(0,d): #input frame j\n",
    "        for i in range(t): # i th template frame aligns with j-th input frame\n",
    "            #6 PPT p.g. 65\n",
    "            Cij= log_gaussian(model_vectors[i],cov_cent[i],data[j])\n",
    "            #print(Cij)\n",
    "            if i-2>=0:\n",
    "                P[i][j]=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i],\n",
    "                            P[i-2][j-1]+T[i-2][i])+Cij\n",
    "            elif i-1>=0:\n",
    "                P[i][j]=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i])+Cij\n",
    "            else:\n",
    "                P[i][j]=P[i][j]+Cij\n",
    "                \n",
    "    #Use DTW cost / frame of input speech, instead of total DTW cost, before determining threshold\n",
    "    # 5 PPT  p.g 32\n",
    "    P=P/d\n",
    "#     print(P.shape)\n",
    "#     print(P[-1][-1])\n",
    "#     print(P)\n",
    "    distance=P[-1][-1]\n",
    "    if get_track:\n",
    "        return distance,traceback(P)\n",
    "    else:\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Kmeans(templates_for_Kmeans,state_number=5):\n",
    "    def fetch_mvectors_and_cov(templates_for_Kmeans,node_state,state_number):\n",
    "        model_vectors=[]#model vector of each state\n",
    "        cov_cent=[]#covariance of each state\n",
    "        node_in_each_state=[]#state number decide sublist number\n",
    "        # node_in_each_state[0] is empty\n",
    "        for state in range(state_number+1):\n",
    "            node_in_each_state.append([])\n",
    "            \n",
    "        for k in range(len(templates_for_Kmeans)):#templates number\n",
    "            # the i th vector of the k th training sequence\n",
    "            for i in range(len(node_state[k])):\n",
    "                j=int(node_state[k][i])#the state of the i th vector\n",
    "                node_in_each_state[j].append(templates_for_Kmeans[k][i])\n",
    "\n",
    "        for j in range(1,state_number+1):\n",
    "            #calculate the initial mean of all the vectors belong to state j\n",
    "            #print(node_in_each_state[j])\n",
    "            m_j=np.mean(node_in_each_state[j],0)\n",
    "            model_vectors.append(m_j)\n",
    "            #transform the list to array\n",
    "            node_in_each_state[j]=np.array(node_in_each_state[j])\n",
    "            #calculate the initial cov of all the vectors belong to state j\n",
    "            cov_temp=np.cov(np.array(node_in_each_state[j]).T)\n",
    "            cov_diagnol=np.diagonal(cov_temp, offset=0, axis1=0, axis2=1)\n",
    "            cov_cent.append(cov_diagnol)\n",
    "            #print(cov_diagnol)\n",
    "        #print(\"yeah~~,CHR is soooo good\")\n",
    "        return model_vectors,cov_cent\n",
    "    \n",
    "    def compute_transition_cost(node_state,state_number):\n",
    "        # 6 PPT p.g 53\n",
    "        #return the transition probability matrix\n",
    "        #have five states+fine(which means Huangrui Chu set 6 states here)\n",
    "        shift_likehood=np.zeros((state_number+1,state_number+1))\n",
    "        state_node_num=np.zeros(state_number+1)\n",
    "        #fetch all the initial state\n",
    "        initial_states=[]\n",
    "        for k in range(len(node_state)):\n",
    "            shift_likehood[0][node_state[k][0]]+=1\n",
    "            \n",
    "        # count the state transition of all the nodes\n",
    "        for k in range(len(node_state)):\n",
    "            for i in range(len(node_state[k])-1):\n",
    "                current_node=node_state[k][i]\n",
    "                next_node=node_state[k][i+1]\n",
    "                shift_likehood[current_node][next_node]+=1 \n",
    "                state_node_num[current_node]+=1\n",
    "            #last node case        \n",
    "            shift_likehood[node_state[k][-2]][node_state[k][-1]]+=1\n",
    "            state_node_num[node_state[k][-1]]+=1\n",
    "        #It is sometimes useful to permit entry directly into later states\n",
    "        for j in range(state_number+1):\n",
    "            #N is the total number of training sequences\n",
    "            N=len(node_state)\n",
    "            #N_0j is the number of training sequences for which\n",
    "            #the first data vector was in the j th state\n",
    "            N_0j=shift_likehood[0][j]\n",
    "            shift_likehood[0][j]=N_0j/N\n",
    "            if N_0j==0:\n",
    "                shift_likehood[0][j]=np.inf\n",
    "            else:\n",
    "                shift_likehood[0][j]=-np.log(shift_likehood[0][j])\n",
    "            \n",
    "        #6 PPT p.g 55\n",
    "        for j in range(1,state_number+1):\n",
    "            for k in range(j,state_number+1):\n",
    "                shift_likehood[j][k]=shift_likehood[j][k]/state_node_num[j]\n",
    "                #transition probability---->transition cost\n",
    "                #T_ij in 6 PPT p.g 58\n",
    "                if shift_likehood[j][k]!=0:\n",
    "                    shift_likehood[j][k]=-np.log(shift_likehood[j][k])\n",
    "                else:\n",
    "                    shift_likehood[j][k]=np.inf\n",
    "        transition_cost=np.array(shift_likehood)\n",
    "        #print(\"likelihood is\")\n",
    "        #print(transition_cost)\n",
    "        return transition_cost\n",
    "    \n",
    "    #initial setup\n",
    "    node_state=[]#each node in which state, all templates together\n",
    "    for k in range(len(templates_for_Kmeans)):#templates number\n",
    "        #now, it is the k th training sequence we are look at\n",
    "        #for initial part, each state have even number of nodes\n",
    "        n_node=len(templates_for_Kmeans[k])//state_number\n",
    "        num_left_nodes=len(templates_for_Kmeans[k])%state_number\n",
    "        #n_node is the N_kj\n",
    "        # to store the node state of k th sequence\n",
    "        current_sample_node_state=np.zeros(len(templates_for_Kmeans[k])).astype(int) \n",
    "        #now, initialize the node state for each node in the k th sequence\n",
    "        for i in range(1,state_number+1):\n",
    "            current_sample_node_state[n_node*(i-1):n_node*i]= int(i)\n",
    "        #left nodes be the last state:\n",
    "        if num_left_nodes!=0:\n",
    "            current_sample_node_state[-num_left_nodes:]= int(state_number)\n",
    "        node_state.append(current_sample_node_state)\n",
    "        #to check my initial node state assignment\n",
    "        #print(node_state[k])\n",
    "        #print(np.bincount(node_state[k], weights=None, minlength=0))\n",
    "        \n",
    "    # By now, for every training squence, we fetch the initial node state\n",
    "    #Next, we need to calculate the model_vectors and cov_cent\n",
    "    model_vectors,covarience=fetch_mvectors_and_cov(templates_for_Kmeans,\n",
    "                                                         node_state,\n",
    "                                                         state_number)\n",
    "    #Next,to simulate the transition structures, we need to calculate the\n",
    "    #transition probability\n",
    "    transition_cost=compute_transition_cost(node_state,state_number)\n",
    "    \n",
    "    #complete set up by iteratively update the model vectors,covariance\n",
    "    #and transition score\n",
    "    previous_best_distance=-np.inf\n",
    "    current_best_distance=0\n",
    "    for j in range(1,100):\n",
    "        #update the node state\n",
    "        for k in range(len(templates_for_Kmeans)):\n",
    "#             print(\"previous\")\n",
    "#             previous_state_count=np.bincount(node_state[k], weights=None, minlength=0)\n",
    "            distance,node_state[k]=Kmean_dtw(model_vectors,templates_for_Kmeans[k]\n",
    "                                    ,transition_cost,covarience,get_track=True)\n",
    "            current_best_distance+=distance\n",
    "#             print(\"later\")\n",
    "#             later_state_count=np.bincount(node_state[k], weights=None, minlength=0)\n",
    "            \n",
    "            \n",
    "        #according to the updated node state, update model_vectors,covarience\n",
    "        model_vectors,covarience=fetch_mvectors_and_cov(templates_for_Kmeans,\n",
    "                                                             node_state,\n",
    "                                                             state_number)\n",
    "        transition_cost=compute_transition_cost(node_state,state_number)\n",
    "        #Convergence is achieved when the total best-alignment error for\n",
    "        #all training sequences does not change significantly with further\n",
    "        #refinement of the model\n",
    "        difference= previous_best_distance-current_best_distance\n",
    "#         print(\"current difference\")\n",
    "#         print(difference)\n",
    "        previous_best_distance=current_best_distance\n",
    "#         print(\"updated previous best distance\")\n",
    "#         print(previous_best_distance)\n",
    "        current_best_distance=0\n",
    "        if abs(difference)<0.0015:\n",
    "            print(\"Use {} iterators to updata\".format(j))\n",
    "            break\n",
    "        \n",
    "    return model_vectors,transition_cost,covarience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Kmeans_templates(foldername,start_instance,end_instance):\n",
    "    #we could also use this function for project 1,2,3 for testing our algorithm\n",
    "    #INPUT:\n",
    "        #foldername: the name of folder where Huangrui save the audio files\n",
    "        #end-start:the number of instance we are expected to use as the templates.\n",
    "    #OUTPUT:\n",
    "        #templates: we can easily fetch the template for the corresponding digit using:\n",
    "                #len(templates)%10+digit\n",
    "    templates_models=[]\n",
    "    templates_likehood=[]\n",
    "    templates_cov=[]\n",
    "    \n",
    "    for digit in range(0,10):\n",
    "        print(\"Huangrui is creating model vector for digit {} using {} sequences\" .format(\n",
    "            digit,end_instance-start_instance))\n",
    "        templates=[]\n",
    "        for i_th_instance in range(start_instance,end_instance):\n",
    "            #print(str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            mfcc=getMFCC2(foldername+\"/\"+str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            templates.append(mfcc)\n",
    "        model,likehood,cov=Kmeans(templates)\n",
    "        #print(model)\n",
    "        templates_models.append(model)\n",
    "        templates_likehood.append(likehood)\n",
    "        templates_cov.append(cov)\n",
    " \n",
    "    return templates_models,templates_likehood,templates_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=[\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Kmeans_templates2(foldername,start_instance,end_instance):\n",
    "    #we could also use this function for project 1,2,3 for testing our algorithm\n",
    "    #INPUT:\n",
    "        #foldername: the name of folder where Huangrui save the audio files\n",
    "        #end-start:the number of instance we are expected to use as the templates.\n",
    "    #OUTPUT:\n",
    "        #templates: we can easily fetch the template for the corresponding digit using:\n",
    "                #len(templates)%10+digit\n",
    "    templates_models=[]\n",
    "    templates_likehood=[]\n",
    "    templates_cov=[]\n",
    "    digits=[\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]\n",
    "    for digit in digits:\n",
    "        print(\"Huangrui is creating model vector for digit {} using {} sequences\" .format(\n",
    "            digit,end_instance-start_instance))\n",
    "        templates=[]\n",
    "        for i_th_instance in range(start_instance,end_instance):\n",
    "            #print(str(digit )+'_'+str(i_th_instance)+'.wav')\n",
    "            mfcc=getMFCC2(foldername+\"/\"+digit+'_'+str(i_th_instance)+'.wav')\n",
    "            templates.append(mfcc)\n",
    "        model,likehood,cov=Kmeans(templates)\n",
    "        #print(model)\n",
    "        templates_models.append(model)\n",
    "        templates_likehood.append(likehood)\n",
    "        templates_cov.append(cov)\n",
    " \n",
    "    return templates_models,templates_likehood,templates_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huangrui is creating model vector for digit zero using 5 sequences\n",
      "Use 14 iterators to updata\n",
      "Huangrui is creating model vector for digit one using 5 sequences\n",
      "Use 15 iterators to updata\n",
      "Huangrui is creating model vector for digit two using 5 sequences\n",
      "Use 11 iterators to updata\n",
      "Huangrui is creating model vector for digit three using 5 sequences\n",
      "Use 10 iterators to updata\n",
      "Huangrui is creating model vector for digit four using 5 sequences\n",
      "Use 9 iterators to updata\n",
      "Huangrui is creating model vector for digit five using 5 sequences\n",
      "Use 11 iterators to updata\n",
      "Huangrui is creating model vector for digit six using 5 sequences\n",
      "Use 7 iterators to updata\n",
      "Huangrui is creating model vector for digit seven using 5 sequences\n",
      "Use 6 iterators to updata\n",
      "Huangrui is creating model vector for digit eight using 5 sequences\n",
      "Use 7 iterators to updata\n",
      "Huangrui is creating model vector for digit nine using 5 sequences\n",
      "Use 7 iterators to updata\n"
     ]
    }
   ],
   "source": [
    "foldername=\"../data\"\n",
    "foldername2=\"../manjunkaidata/templates\"\n",
    "templates_models,templates_likehood,templates_cov=create_Kmeans_templates2(foldername2,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername3=\"../manjunkaidata/queries\"\n",
    "test_data,max_length=create_templates2(foldername3,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKMeans_HMM_accuracy(templates_models,test_data,templates_likehood,templates_cov):\n",
    "    #K-means HMM recognition\n",
    "    import numpy as np\n",
    "\n",
    "    #main\n",
    "    accuracy=0\n",
    "    for j in range(len(test_data)):\n",
    "        current_digit=j%10\n",
    "        smallest_distance=[1000000,0]\n",
    "        for i in range(10):\n",
    "            distance=Kmean_dtw(templates_models[i],test_data[j],templates_likehood[i],templates_cov[i])\n",
    "            if distance<smallest_distance[0]:\n",
    "                smallest_distance[0]=distance\n",
    "                smallest_distance[1]=i\n",
    "        recoginized_result=smallest_distance[1]\n",
    "        if current_digit==recoginized_result:\n",
    "            accuracy+=1\n",
    "        print(current_digit,'recognized as:',recoginized_result)\n",
    "    print('accuracy:',accuracy/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 recognized as: 0\n",
      "1 recognized as: 1\n",
      "2 recognized as: 2\n",
      "3 recognized as: 3\n",
      "4 recognized as: 4\n",
      "5 recognized as: 5\n",
      "6 recognized as: 6\n",
      "7 recognized as: 7\n",
      "8 recognized as: 8\n",
      "9 recognized as: 1\n",
      "0 recognized as: 0\n",
      "1 recognized as: 1\n",
      "2 recognized as: 2\n",
      "3 recognized as: 3\n",
      "4 recognized as: 4\n",
      "5 recognized as: 5\n",
      "6 recognized as: 6\n",
      "7 recognized as: 1\n",
      "8 recognized as: 8\n",
      "9 recognized as: 9\n",
      "0 recognized as: 0\n",
      "1 recognized as: 1\n",
      "2 recognized as: 2\n",
      "3 recognized as: 3\n",
      "4 recognized as: 4\n",
      "5 recognized as: 5\n",
      "6 recognized as: 5\n",
      "7 recognized as: 7\n",
      "8 recognized as: 8\n",
      "9 recognized as: 1\n",
      "0 recognized as: 0\n",
      "1 recognized as: 1\n",
      "2 recognized as: 2\n",
      "3 recognized as: 3\n",
      "4 recognized as: 4\n",
      "5 recognized as: 5\n",
      "6 recognized as: 6\n",
      "7 recognized as: 1\n",
      "8 recognized as: 8\n",
      "9 recognized as: 9\n",
      "0 recognized as: 0\n",
      "1 recognized as: 1\n",
      "2 recognized as: 2\n",
      "3 recognized as: 3\n",
      "4 recognized as: 4\n",
      "5 recognized as: 5\n",
      "6 recognized as: 6\n",
      "7 recognized as: 7\n",
      "8 recognized as: 8\n",
      "9 recognized as: 1\n",
      "accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "getKMeans_HMM_accuracy(templates_models,test_data,templates_likehood,templates_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
