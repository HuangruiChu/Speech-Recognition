{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import GMM and other library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GMMHMM import *\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_pickle(model,filepath,save_name):\n",
    "    # Dump the trained decision tree classifier with Pickle\n",
    "    pkl_filename = filepath+save_name+'.pkl'\n",
    "\n",
    "    # Open the file to save as pkl file\n",
    "    model_pkl = open(pkl_filename, 'wb')\n",
    "    pickle.dump(model,model_pkl)\n",
    "\n",
    "    # Close the pickle instances\n",
    "    model_pkl.close()\n",
    "def load_pickle(filepath,save_name):\n",
    "    classification_pkl_filename = filepath+\"/\"+save_name+'.pkl'\n",
    "    classification_model_pkl = open(classification_pkl_filename, 'rb')\n",
    "    classification_model = pickle.load(classification_model_pkl)\n",
    "    #print (\"Loaded HMM model: \", classification_model)\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_digit_GMMHMM(filepath,filenames):\n",
    "    GMMHMMs={}\n",
    "    for digit in filenames:\n",
    "        print(\"Huangrui is loading the digit {} GMMHMM\".format(digit))\n",
    "        current_digit_GMMHMM=load_pickle(filepath,str(digit))\n",
    "        GMMHMMs[str(digit)]=current_digit_GMMHMM\n",
    "    return GMMHMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huangrui is loading the digit 0 GMMHMM\n",
      "Huangrui is loading the digit 1 GMMHMM\n",
      "Huangrui is loading the digit 2 GMMHMM\n",
      "Huangrui is loading the digit 3 GMMHMM\n",
      "Huangrui is loading the digit 4 GMMHMM\n",
      "Huangrui is loading the digit 5 GMMHMM\n",
      "Huangrui is loading the digit 6 GMMHMM\n",
      "Huangrui is loading the digit 7 GMMHMM\n",
      "Huangrui is loading the digit 8 GMMHMM\n",
      "Huangrui is loading the digit 9 GMMHMM\n",
      "Huangrui is loading the digit silence GMMHMM\n"
     ]
    }
   ],
   "source": [
    "filepath=\"new_project6_models/\"\n",
    "filenames=[0,1,2,3,4,5,6,7,8,9,\"silence\"]\n",
    "#filenames=[0,1,2,3,4,5,6,7,8,9]\n",
    "GMMHMMS=load_all_digit_GMMHMM(filepath,filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.07374347, 2.64380793, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.01878577, 3.98403354, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.01959566, 3.94222885],\n",
       "       [0.        , 0.        , 0.        , 0.        , 3.94222885]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMMHMMS[\"0\"].hmm.transition_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class LexNode:\n",
    "    def __init__(self, val,word):\n",
    "        #这里的VAL 是GMM 哦\n",
    "        self.val = val\n",
    "        self.word= word\n",
    "        self.children = []\n",
    "        # set the property so that we can differentiate the start node, normal(between) node and end of word node\n",
    "        # 0: normal node\n",
    "        # 1: start node\n",
    "        # 2: end-of-word node\n",
    "        self.property = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildLextree:\n",
    "    def __init__(self, dic):\n",
    "        self.dic2words(dic)\n",
    "        zeros=np.zeros([39])\n",
    "        ones=np.zeros([39])+1\n",
    "        mix_of_all_states=[]\n",
    "        #create a fine GMM \n",
    "        fine_GMM=mixInfo()\n",
    "        fine_GMM.Gaussian_mean.append(zeros)\n",
    "        #fine_GMM.Gaussian_mean.append(zeros)\n",
    "        fine_GMM.Gaussian_var.append(ones)\n",
    "        #fine_GMM.Gaussian_var.append(ones)\n",
    "        fine_GMM.Gaussian_weight=[1]\n",
    "        #translate from list to np array\n",
    "        fine_GMM.Gaussian_mean=np.array(fine_GMM.Gaussian_mean)\n",
    "        fine_GMM.Gaussian_var=np.array(fine_GMM.Gaussian_var)\n",
    "        fine_GMM.Num_of_Gaussian = 1\n",
    "        self.tree=LexNode(fine_GMM,\"*\")\n",
    "        # dummy symbol for the root of the tree\n",
    "        self.tree.property = 1\n",
    "        n_words = len(self.words)\n",
    "        word_lens = [w.hmm.N for w in self.words]\n",
    "        print(\"There are {} words in this dictionary\".format(len(self.words)))\n",
    "        \n",
    "    def dic2words(self,dic):\n",
    "        self.words=[]\n",
    "        self.keys=list(dic.keys())\n",
    "        self.transition_cost={}\n",
    "        for key in self.keys:\n",
    "            self.words.append(dic[key])\n",
    "            self.transition_cost[key]=dic[key].hmm.transition_cost\n",
    "        \n",
    "    def append_lex_node(self,parent, child):\n",
    "        #This function just append the child node to the paretn node\n",
    "        #It would check whether the parent is a LexNode!\n",
    "        assert type(parent) is LexNode and type(child) is LexNode\n",
    "        parent.children.append(child)\n",
    "    \n",
    "    def build_lextree(self):\n",
    "        #this is the function to build the lextree from the self.words and root node \"*\"\n",
    "        for i in range(len(self.words)):\n",
    "            word=self.words[i]\n",
    "            key=self.keys[i]\n",
    "            previous_node=LexNode(word.hmm.mix[0],key)\n",
    "            self.tree.children.append(previous_node)\n",
    "            for j in range(1,word.hmm.N):\n",
    "                current_node=LexNode(word.hmm.mix[j],key)\n",
    "                previous_node.children.append(current_node)\n",
    "                previous_node=current_node\n",
    "            previous_node.children.append(self.tree)\n",
    "            previous_node.property=2\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 words in this dictionary\n"
     ]
    }
   ],
   "source": [
    "buildlextree=BuildLextree(GMMHMMS)\n",
    "buildlextree.build_lextree()\n",
    "lextree=buildlextree.tree\n",
    "transition_cost=buildlextree.transition_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinousSpeechRecognition():\n",
    "    def __init__(self):\n",
    "        self.lextree=None\n",
    "        self.dist_fun=None\n",
    "        \n",
    "    def fit(self,lextree,transition_cost):\n",
    "        self.lextree=lextree\n",
    "        assert type(self.lextree) is LexNode\n",
    "        self.nodes = []\n",
    "        self.get_nodes(self.lextree)\n",
    "        self.initial_nodes_idx=[]\n",
    "        for i in self.initial_nodes:\n",
    "            self.initial_nodes_idx.append(self.nodes.index(i))\n",
    "        # get self.transitions\n",
    "        self.transition_cost=transition_cost\n",
    "        self.get_parent = {}\n",
    "        self.get_children={}\n",
    "        to_children={}\n",
    "        n_nodes = len(self.nodes)\n",
    "        self.word_ends = []\n",
    "        # record the end idx of each words, therefore, at the end of the vertibe , we can get the costs of each word\n",
    "        for i in range(n_nodes):\n",
    "            n = self.nodes[i]\n",
    "            if n.property == 2:\n",
    "                self.word_ends.append(i)\n",
    "            self.get_children[i]=[]\n",
    "            # add transition if there is any. to get the parent node of current node\n",
    "            if len(n.children) > 0:\n",
    "                for child in n.children:\n",
    "                    self.get_children[i].append(self.nodes.index(child))\n",
    "                    self.get_parent[self.nodes.index(child)] = i\n",
    "                \n",
    "    def get_nodes(self, lexnode):\n",
    "        self.nodes=[]\n",
    "        self.states=[]\n",
    "        self.initial_nodes=[]\n",
    "        words=lexnode.children\n",
    "        self.states.append(0)\n",
    "        self.nodes.append(lexnode)\n",
    "        for word in words:\n",
    "            state=0\n",
    "            current_GMM=word\n",
    "            self.initial_nodes.append(current_GMM)\n",
    "            while current_GMM.property!=2:\n",
    "                state+=1\n",
    "                self.states.append(state)\n",
    "                self.nodes.append(current_GMM)\n",
    "                current_GMM=current_GMM.children[0]\n",
    "            state+=1\n",
    "            self.states.append(state)\n",
    "            self.nodes.append(current_GMM)\n",
    "    \n",
    "    def idx2words(self,result):\n",
    "        sentence=\"\"\n",
    "        for idx in result:\n",
    "            sentence+=self.nodes[idx].word\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def traceback4or7(self,z_level,c):\n",
    "        if len(z_level)>=7:\n",
    "            min7=min(z_level[6][self.word_ends,c])\n",
    "            min4=min(z_level[3][self.word_ends,c])\n",
    "            \n",
    "            if min7<min4:\n",
    "                start=6\n",
    "            else:\n",
    "                start=3\n",
    "        else:\n",
    "            start=3\n",
    "            \n",
    "        final_result=\"\"\n",
    "        for i in range(start,-1,-1):\n",
    "            current_digit,c=self._traceback(z_level[i],c)\n",
    "            final_result=current_digit+final_result\n",
    "        return final_result\n",
    "    \n",
    "    def traceback(self,z_matrix,c):\n",
    "\n",
    "        final_result=\"\"\n",
    "        while c>0:\n",
    "            current_digit,c=self._traceback(z_matrix,c)\n",
    "            #print(current_digit)\n",
    "            final_result=current_digit+final_result\n",
    "\n",
    "        return final_result\n",
    "    \n",
    "    def _traceback(self,z_matrix,c):\n",
    "        min_idx=np.argmin(z_matrix[self.word_ends,c])\n",
    "        #print(min_idx)\n",
    "        r=self.word_ends[min_idx]\n",
    "        while r>0 and c>0:\n",
    "            to_check=[z_matrix[r,c-1], \n",
    "                  z_matrix[self.get_parent[r],c-1],]\n",
    "            track=np.argmin(to_check)\n",
    "            if track==0:\n",
    "                c-=1\n",
    "            elif track==1:\n",
    "                c-=1\n",
    "                r=self.get_parent[r]\n",
    "            else:\n",
    "                r=self.get_parent[r]\n",
    "\n",
    "        #print(\"current word start from {} th input\".format(result))\n",
    "        return self.nodes[self.word_ends[min_idx]].word,c\n",
    "    \n",
    "    \n",
    "    def digit_vertibe47(self,data,loop_cost=300):\n",
    "        #set different types of cost\n",
    "        \n",
    "        loop_cost = loop_cost\n",
    "        \n",
    "        \n",
    "        zero39=np.zeros([data.shape[1]])\n",
    "        data=np.vstack([zero39,data])\n",
    "        # initialize cost matrix\n",
    "        n_cols = len(data)\n",
    "        n_rows = len(self.nodes)\n",
    "        costs = np.full([n_rows,n_cols], np.inf)\n",
    "        mute=np.zeros(n_rows)\n",
    "        # * to all other nodes\n",
    "        initial_cost=copy.deepcopy(costs)\n",
    "        initial_cost[0,0]=0\n",
    "\n",
    "        #token=[x=c,y=idx,z=?]\n",
    "        y_level=[mute]\n",
    "        z_level=[initial_cost]\n",
    "        for c in range(1,n_cols):\n",
    "            next_z_level=[]\n",
    "            next_y_level=[]\n",
    "            for current_possible_choice in range(len(z_level)):\n",
    "                z_matrix=z_level[current_possible_choice]\n",
    "                current_nodes=y_level[current_possible_choice]\n",
    "                next_to_check_nodes=copy.deepcopy(mute)\n",
    "                #update the y level costs\n",
    "                for r in range(1,n_rows):\n",
    "                    distance=mixture_log_gaussian(self.nodes[r].val,data[c])\n",
    "                    \n",
    "                    if current_nodes[r]:\n",
    "                        to_check=[( z_matrix[self.get_parent[r]][c-1]+\n",
    "                            self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]]\n",
    "                            )]\n",
    "                    elif current_nodes[self.get_parent[r]]:\n",
    "                        to_check=[z_matrix[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]]]\n",
    "                    elif current_nodes[self.get_parent[r]] and current_nodes[r]:\n",
    "                        to_check=[np.inf]\n",
    "                        next_to_check_nodes[r]=1\n",
    "                    else:\n",
    "                        to_check=[z_matrix[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]], # self transition\n",
    "                                 (z_matrix[self.get_parent[r]][c-1]+\n",
    "                                self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]])]\n",
    "\n",
    "                    z_matrix[r][c]= min(to_check)+distance\n",
    "                    if distance>500:#建议设置成500， 不然出错的几率会变大\n",
    "                        next_to_check_nodes[r]=1\n",
    "                next_y_level.append(next_to_check_nodes)\n",
    "                #现在查看是否有新的词可以产生\n",
    "                min_idx=np.argmin(z_matrix[:,c])\n",
    "                min_cost=min(z_matrix[:,c])\n",
    "                #print(\"min cost is {}, idx is {}\".format(min_cost,min_idx))\n",
    "                if min_idx in self.word_ends:\n",
    "                    if len(z_level)-1>current_possible_choice:\n",
    "                        #说明已经存在了这个新词\n",
    "                        next_z=z_level[current_possible_choice+1]\n",
    "                        next_z[0,c]=min_cost+loop_cost\n",
    "                        \n",
    "                    elif len(z_level)<7:\n",
    "                        #可以开新词\n",
    "                        new_z_matrix=copy.deepcopy(costs)\n",
    "                        new_z_matrix[0,c]=min_cost+loop_cost\n",
    "                        z_level.append(new_z_matrix)\n",
    "                        next_y_level.append(copy.deepcopy(mute))\n",
    "                                       \n",
    "            y_level=next_y_level\n",
    "        \n",
    "        final_result=self.traceback4or7(z_level,c)\n",
    "        print(\"final_result is {}\".format(final_result))\n",
    "        return final_result\n",
    "    \n",
    "    \n",
    "    def digit_vertibe(self,data,threshold=400,loop_cost=300):\n",
    "        #set different types of cost        \n",
    "        loop_cost = loop_cost\n",
    "        \n",
    "        zero39=np.zeros([data.shape[1]])\n",
    "        data=np.vstack([zero39,data])\n",
    "        # initialize cost matrix\n",
    "        n_cols = len(data)\n",
    "        n_rows = len(self.nodes)\n",
    "        trellis = np.full([n_rows,n_cols], np.inf)\n",
    "        trellis[0][0]=0\n",
    "        def pruning(column,threshold):\n",
    "            best=min(column)\n",
    "            for i in range(len(column)):\n",
    "                if column[i]>best+threshold:\n",
    "                    column[i]= np.inf\n",
    "        \n",
    "        for c in range(1,n_cols):\n",
    "            # pruning\n",
    "            if c>=3:\n",
    "                column=trellis[:,c-1]\n",
    "                pruning(column,threshold)\n",
    "            for r in range(1,n_rows):\n",
    "                distance=mixture_log_gaussian(self.nodes[r].val,data[c])\n",
    "\n",
    "                #to check information\n",
    "                to_check=[trellis[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]], # self transition\n",
    "                         (trellis[self.get_parent[r]][c-1]+\n",
    "                        self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]])]\n",
    "                \n",
    "                if not min (to_check)==np.inf:\n",
    "                    trellis[r][c]= min(to_check)+distance\n",
    "                \n",
    "            #现在查看是否有新的词可以产生\n",
    "            min_idx=np.argmin(trellis[:,c])\n",
    "            min_cost=min(trellis[:,c])\n",
    "            #print(\"min cost is {}, idx is {}\".format(min_cost,min_idx))\n",
    "            if min_idx in self.word_ends and min_cost!=np.inf:\n",
    "                #print(\"a new word start\")\n",
    "                trellis[0,c]=min_cost+loop_cost\n",
    "                \n",
    "        final_result=self.traceback(trellis,c)\n",
    "        print(\"final_result is {}\".format(final_result))\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr=ContinousSpeechRecognition()\n",
    "csr.fit(lextree,transition_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the record project6 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result is silence0987354321silence\n",
      "Huangrui recognize 0987654321_8 as silence0987354321silence\n"
     ]
    }
   ],
   "source": [
    "file_folder=\"project6data/\"\n",
    "wavefile=\"0987654321_8.wav\"\n",
    "\n",
    "digit=wavefile[:-4]\n",
    "data=getMFCC2(file_folder+wavefile)\n",
    "digit_result=csr.digit_vertibe(data)\n",
    "print(\"Huangrui recognize {} as {}\".format(digit,digit_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start test problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result is silence123456\n",
      "Huangrui recognize 123456 as silence123456\n",
      "final_result is 296789436\n",
      "Huangrui recognize 25678543 as 296789436\n",
      "final_result is silence37274920\n",
      "Huangrui recognize 37274921 as silence37274920\n",
      "final_result is silence5555\n",
      "Huangrui recognize 55555 as silence5555\n",
      "final_result is 96890372344\n",
      "Huangrui recognize 6890372344 as 96890372344\n",
      "final_result is silence729843479246\n",
      "Huangrui recognize 72184347924 as silence729843479246\n",
      "final_result is silence73433321903776\n",
      "Huangrui recognize 7343332190377 as silence73433321903776\n",
      "final_result is silence82121763426\n",
      "Huangrui recognize 8212176342 as silence82121763426\n",
      "final_result is 9826414052002\n",
      "Huangrui recognize 826414052002 as 9826414052002\n",
      "final_result is silence911386\n",
      "Huangrui recognize 911385 as silence911386\n"
     ]
    }
   ],
   "source": [
    "file_folder=\"test_data/problem2/\"\n",
    "wavefiles=os.listdir(file_folder)\n",
    "for wavefile in wavefiles:\n",
    "    digit=wavefile[:-4]\n",
    "    data=getMFCC2(file_folder+wavefile)\n",
    "    digit_result=csr.digit_vertibe(data,loop_cost=300)\n",
    "    print(\"Huangrui recognize {} as {}\".format(digit,digit_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui Calculate the final accuracy to be: 83/89=0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
